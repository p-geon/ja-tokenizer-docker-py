{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6688d68f",
   "metadata": {},
   "source": [
    "# Word2Vec\n",
    "\n",
    "word2vec のベクトル計算テストです。日本語エンティティベクトルがやや重いので、読み込みに数秒〜十数秒かかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b7066",
   "metadata": {},
   "source": [
    "## 初期化\n",
    "\n",
    "環境変数をまたいで、Docker内のエンティティベクトルのバイナリファイルを指定しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6aacae24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "entity_filename = os.environ.get('ENTITY_FILENAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7e210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b05f2c",
   "metadata": {},
   "source": [
    "## Word2Vec クラス\n",
    "\n",
    "シンプルな最低限の作りです。改造すると similarity とかも簡単に計算できるはずです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e38abe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(object):\n",
    "    def __init__(self, bin_entity_filename: str):\n",
    "        model_path = bin_entity_filename\n",
    "        self.model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "\n",
    "\n",
    "    def __call__(self, word: str) -> object:\n",
    "        try:  # existent word\n",
    "            v = self.model.get_vector(word)\n",
    "            return v\n",
    "        except KeyError as k: # non-existent word\n",
    "            return k\n",
    "        \n",
    "w2v = Word2Vec(entity_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0016ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vector(word: str) -> None:\n",
    "    vec = w2v.__call__(word)\n",
    "    \n",
    "    if(type(vec)==np.ndarray):\n",
    "        print(f\"{word}: \", type(vec), vec.shape, vec[0:10])\n",
    "    else:\n",
    "        print(f\"{word} is non-existent word.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eeaa28",
   "metadata": {},
   "source": [
    "## 実行\n",
    "\n",
    "引数に適当な単語を入れると、その単語のベクトルを表示します。辞書に存在しない単語の場合は `Error` になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d405226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ピジョン:  <class 'numpy.ndarray'> (200,) [ 0.18742366  0.07586656  0.03849505  0.38004303 -0.00524301 -0.20294596\n",
      "  0.20340575  0.49917793 -0.2951132  -0.08509478]\n",
      "ジョンレノン:  <class 'numpy.ndarray'> (200,) [-0.16034932  0.01255404 -0.04605854 -0.00191343 -0.05804803  0.02341573\n",
      " -0.07098377 -0.00638543  0.00649883 -0.04386802]\n",
      "ピジョレオン is non-existent word.\n"
     ]
    }
   ],
   "source": [
    "check_vector(word=\"ピジョン\")\n",
    "check_vector(word=\"ジョンレノン\")\n",
    "check_vector(word=\"ピジョレオン\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
